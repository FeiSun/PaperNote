# Text Representation



## Transfor, Pretrain

#### [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

* pretrain for nlp task
* Maked LM + next sentence +  transformer

#### ELMO

* contexualized word embedding
* 



